{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHQ/3+p8QE9uGTlSF52rYi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awaisarif18/PDC-Assignments/blob/main/PDC_Assignment01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_assignment.cu\n",
        "/*\n",
        " * ======================================================================\n",
        " * PDC Lab Assignment #1: Introduction to CUDA\n",
        " *\n",
        " * This single file contains the code for all three parts of the assignment:\n",
        " * 1. Hello GPU: Demonstrates basic kernel launch and thread indexing.\n",
        " * 2. Vector Addition: Compares CPU vs. GPU performance for vector addition.\n",
        " * 3. Image Inversion: Compares CPU vs. GPU performance for image processing.\n",
        " *\n",
        " * How to compile in Google Colab (after running %%writefile):\n",
        " * !nvcc cuda_assignment.cu -o assignment_runner\n",
        " *\n",
        " * How to run:\n",
        " * !./assignment_runner\n",
        " *\n",
        " * (Make sure to upload 'input.jpg' for Part 3 to work!)\n",
        " * ======================================================================\n",
        " */\n",
        "\n",
        "// Common C/C++ headers\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "#include <chrono> // For C++ high-resolution timers (CPU)\n",
        "\n",
        "// CUDA runtime header\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// STB Image headers for loading/saving images (Part 3)\n",
        "// We must define these implementation macros in *one* C/C++ file\n",
        "// before including the headers. This is that file.\n",
        "#define STB_IMAGE_IMPLEMENTATION\n",
        "#include \"stb_image.h\"\n",
        "#define STB_IMAGE_WRITE_IMPLEMENTATION\n",
        "#include \"stb_image_write.h\"\n",
        "\n",
        "/*\n",
        " * ======================================================================\n",
        " * Helper Macro for CUDA Error Checking\n",
        " * ======================================================================\n",
        " *\n",
        " * This macro wraps every CUDA API call to check for errors.\n",
        " * If a CUDA call fails, it prints the error message, file, and line number,\n",
        " * and then exits the program. This is extremely helpful for debugging.\n",
        " */\n",
        "#define CHECK_CUDA(call) do { \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        fprintf(stderr, \"CUDA Error at %s:%d - %s\\n\", __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "        exit(1); \\\n",
        "    } \\\n",
        "} while (0)\n",
        "\n",
        "/*\n",
        " * ======================================================================\n",
        " * Part 1: Hello GPU with CUDA\n",
        " * ======================================================================\n",
        " *\n",
        " * __global__ keyword: This tells the CUDA compiler (NVCC) that this\n",
        " * function is a \"kernel\" - code that will run on the GPU.\n",
        " * It is called from the host (CPU) and executed by many threads on the device (GPU).\n",
        " */\n",
        "__global__ void helloGpu() {\n",
        "    /*\n",
        "     * Built-in CUDA variables:\n",
        "     * - threadIdx.x: The ID of the current thread within its block (e.g., 0, 1, ..., 255).\n",
        "     * - blockIdx.x:  The ID of the current block within the grid (e.g., 0, 1, ...).\n",
        "     * - blockDim.x:  The number of threads in one block (e.g., 256).\n",
        "     *\n",
        "     * We can calculate a unique global ID for every thread in the grid:\n",
        "     * global_thread_id = (block_id * threads_per_block) + thread_id\n",
        "     */\n",
        "    int global_tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // printf is available inside kernels (on modern GPUs)\n",
        "    // It's helpful for debugging, but can be slow if all threads print.\n",
        "    printf(\"Hello from thread %d (Block: %d, Thread: %d)\\n\",\n",
        "           global_tid, blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "/*\n",
        " * ======================================================================\n",
        " * Part 2: Vector Addition\n",
        " * ======================================================================\n",
        " */\n",
        "\n",
        "// --- CPU Implementation ---\n",
        "// A standard C++ function that runs on the host (CPU).\n",
        "void cpuVectorAdd(int N, float* a, float* b, float* c) {\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// --- GPU Implementation ---\n",
        "// A CUDA kernel that runs on the device (GPU).\n",
        "__global__ void gpuVectorAdd(int N, float* d_a, float* d_b, float* d_c) {\n",
        "    // Calculate the global thread ID.\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    /*\n",
        "     * Grid-Stride Loop:\n",
        "     * This is a common and robust pattern. Instead of launching exactly N threads,\n",
        "     * we launch a reasonable number of threads and have each thread\n",
        "     * loop and process multiple elements.\n",
        "     *\n",
        "     * This has two benefits:\n",
        "     * 1. It works even if N is larger than the max number of threads we can launch.\n",
        "     * 2. It's often more efficient.\n",
        "     *\n",
        "     * gridDim.x * blockDim.x = Total number of threads in the grid.\n",
        "     * We increment our index 'i' by this total stride in each loop.\n",
        "     */\n",
        "    for (int i = idx; i < N; i += gridDim.x * blockDim.x) {\n",
        "        d_c[i] = d_a[i] + d_b[i];\n",
        "    }\n",
        "\n",
        "    /*\n",
        "     * --- Simpler (but less robust) alternative: ---\n",
        "     * // Check boundary condition\n",
        "     * if (idx < N) {\n",
        "     * d_c[idx] = d_a[idx] + b_c[idx];\n",
        "     * }\n",
        "     * This also works, but requires launching at least N threads.\n",
        "     * The grid-stride loop is generally preferred.\n",
        "     */\n",
        "}\n",
        "\n",
        "/*\n",
        " * ======================================================================\n",
        " * Part 3: Image Inversion\n",
        " * ======================================================================\n",
        " */\n",
        "\n",
        "// --- CPU Implementation ---\n",
        "void cpuImageInvert(int width, int height, int channels, unsigned char* in_data, unsigned char* out_data) {\n",
        "    int num_pixels = width * height;\n",
        "\n",
        "    // Loop through every pixel\n",
        "    for (int p = 0; p < num_pixels; ++p) {\n",
        "        int base_idx = p * channels;\n",
        "        // Invert the R, G, B channels\n",
        "        out_data[base_idx + 0] = 255 - in_data[base_idx + 0]; // Red\n",
        "        out_data[base_idx + 1] = 255 - in_data[base_idx + 1]; // Green\n",
        "        out_data[base_idx + 2] = 255 - in_data[base_idx + 2]; // Blue\n",
        "\n",
        "        // If there's an Alpha channel (4th channel), just copy it.\n",
        "        // We don't want to invert transparency.\n",
        "        if (channels == 4) {\n",
        "            out_data[base_idx + 3] = in_data[base_idx + 3]; // Alpha\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// --- GPU Implementation ---\n",
        "__global__ void gpuImageInvert(int width, int height, int channels, unsigned char* d_in, unsigned char* d_out) {\n",
        "    int num_pixels = width * height;\n",
        "\n",
        "    // Calculate the global thread ID, which will correspond to the *pixel* index.\n",
        "    int pixel_idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Use a grid-stride loop to process all pixels\n",
        "    for (int p = pixel_idx; p < num_pixels; p += gridDim.x * blockDim.x) {\n",
        "        int base_idx = p * channels;\n",
        "\n",
        "        // Invert R, G, B\n",
        "        d_out[base_idx + 0] = 255 - d_in[base_idx + 0];\n",
        "        d_out[base_idx + 1] = 255 - d_in[base_idx + 1];\n",
        "        d_out[base_idx + 2] = 255 - d_in[base_idx + 2];\n",
        "\n",
        "        // Copy Alpha if it exists\n",
        "        if (channels == 4) {\n",
        "            d_out[base_idx + 3] = d_in[base_idx + 3];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/*\n",
        " * ======================================================================\n",
        " * Main Function\n",
        " * ======================================================================\n",
        " *\n",
        " * This runs on the host (CPU) and coordinates all parts.\n",
        " */\n",
        "int main() {\n",
        "    printf(\"===========================================\\n\");\n",
        "    printf(\"PDC Lab Assignment #1: CUDA Introduction\\n\");\n",
        "    printf(\"===========================================\\n\\n\");\n",
        "\n",
        "    // Get basic information about the GPU\n",
        "    int deviceCount;\n",
        "    CHECK_CUDA(cudaGetDeviceCount(&deviceCount));\n",
        "    if (deviceCount == 0) {\n",
        "        fprintf(stderr, \"No CUDA-capable device found!\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "    cudaDeviceProp devProp;\n",
        "    CHECK_CUDA(cudaGetDeviceProperties(&devProp, 0));\n",
        "    printf(\"Using GPU: %s\\n\\n\", devProp.name);\n",
        "\n",
        "\n",
        "    /*\n",
        "     * ----------------------------------------\n",
        "     * Part 1: Hello GPU\n",
        "     * ----------------------------------------\n",
        "     */\n",
        "    printf(\"--- Part 1: Hello GPU ---\\n\");\n",
        "\n",
        "    // Launch configuration: <<< Grid, Blocks >>>\n",
        "    // We launch 2 blocks, and each block has 4 threads.\n",
        "    // Total threads = 2 * 4 = 8\n",
        "    dim3 grid_p1(2);\n",
        "    dim3 blocks_p1(4);\n",
        "    helloGpu<<<grid_p1, blocks_p1>>>();\n",
        "\n",
        "    // We MUST wait for the kernel to finish before the program\n",
        "    // continues. `cudaDeviceSynchronize` waits for all preceding\n",
        "    // GPU tasks to complete.\n",
        "    CHECK_CUDA(cudaDeviceSynchronize());\n",
        "    printf(\"Part 1 Complete.\\n\\n\");\n",
        "\n",
        "\n",
        "    /*\n",
        "     * ----------------------------------------\n",
        "     * Part 2: Vector Addition\n",
        "     * ----------------------------------------\n",
        "     */\n",
        "    printf(\"--- Part 2: Vector Addition (N = 10,000,000) ---\\n\");\n",
        "\n",
        "    int N = 10000000;\n",
        "    size_t bytes = N * sizeof(float);\n",
        "\n",
        "    // 1. Allocate Host (CPU) memory\n",
        "    float* h_a = (float*)malloc(bytes);\n",
        "    float* h_b = (float*)malloc(bytes);\n",
        "    float* h_c_cpu = (float*)malloc(bytes); // For CPU result\n",
        "    float* h_c_gpu = (float*)malloc(bytes); // For GPU result\n",
        "\n",
        "    if (!h_a || !h_b || !h_c_cpu || !h_c_gpu) {\n",
        "        fprintf(stderr, \"Failed to allocate host memory for Part 2!\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // 2. Initialize Host data\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        h_a[i] = (float)rand() / RAND_MAX; // Random float 0.0-1.0\n",
        "        h_b[i] = (float)rand() / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // 3. --- Run CPU Version ---\n",
        "    printf(\"Running CPU vector addition...\\n\");\n",
        "    auto start_cpu = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    cpuVectorAdd(N, h_a, h_b, h_c_cpu);\n",
        "\n",
        "    auto stop_cpu = std::chrono::high_resolution_clock::now();\n",
        "    auto duration_ms_cpu = std::chrono::duration_cast<std::chrono::microseconds>(stop_cpu - start_cpu).count() / 1000.0;\n",
        "    printf(\"CPU Time: %.3f ms\\n\", duration_ms_cpu);\n",
        "\n",
        "    // 4. --- Run GPU Version ---\n",
        "    printf(\"Running GPU vector addition...\\n\");\n",
        "\n",
        "    // 4a. Allocate Device (GPU) memory\n",
        "    float* d_a, * d_b, * d_c;\n",
        "    CHECK_CUDA(cudaMalloc(&d_a, bytes));\n",
        "    CHECK_CUDA(cudaMalloc(&d_b, bytes));\n",
        "    CHECK_CUDA(cudaMalloc(&d_c, bytes));\n",
        "\n",
        "    // 4b. Create CUDA events for timing\n",
        "    // This is the accurate way to time GPU execution.\n",
        "    cudaEvent_t start_gpu, stop_gpu;\n",
        "    CHECK_CUDA(cudaEventCreate(&start_gpu));\n",
        "    CHECK_CUDA(cudaEventCreate(&stop_gpu));\n",
        "\n",
        "    // 4c. Record start event\n",
        "    CHECK_CUDA(cudaEventRecord(start_gpu));\n",
        "\n",
        "    // 4d. Copy data from Host (CPU) to Device (GPU)\n",
        "    CHECK_CUDA(cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK_CUDA(cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // 4e. Launch the GPU Kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    // Calculate number of blocks needed to cover all N elements\n",
        "    // This is a standard \"ceiling\" calculation: (N + 255) / 256\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    gpuVectorAdd<<<blocksPerGrid, threadsPerBlock>>>(N, d_a, d_b, d_c);\n",
        "\n",
        "    // 4f. Copy results from Device (GPU) back to Host (CPU)\n",
        "    CHECK_CUDA(cudaMemcpy(h_c_gpu, d_c, bytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // 4g. Record stop event and synchronize\n",
        "    CHECK_CUDA(cudaEventRecord(stop_gpu));\n",
        "    CHECK_CUDA(cudaEventSynchronize(stop_gpu)); // Wait for stop event to finish\n",
        "\n",
        "    // 4h. Calculate and print GPU time\n",
        "    float duration_ms_gpu = 0;\n",
        "    CHECK_CUDA(cudaEventElapsedTime(&duration_ms_gpu, start_gpu, stop_gpu));\n",
        "    printf(\"GPU Time: %.3f ms\\n\", duration_ms_gpu);\n",
        "\n",
        "    // 5. --- Verification and Speedup ---\n",
        "    printf(\"Verifying results...\\n\");\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < 100; ++i) { // Check first 100 elements\n",
        "        if (fabs(h_c_cpu[i] - h_c_gpu[i]) > 1e-5) {\n",
        "            printf(\"Error at index %d: CPU=%.5f, GPU=%.5f\\n\", i, h_c_cpu[i], h_c_gpu[i]);\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    if (correct) {\n",
        "        printf(\"Results are correct!\\n\");\n",
        "        printf(\"Speedup (CPU Time / GPU Time): %.2fx\\n\", duration_ms_cpu / duration_ms_gpu);\n",
        "    } else {\n",
        "        printf(\"Results are INCORRECT!\\n\");\n",
        "    }\n",
        "\n",
        "    // 6. --- Cleanup Part 2 ---\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c_cpu);\n",
        "    free(h_c_gpu);\n",
        "    CHECK_CUDA(cudaFree(d_a));\n",
        "    CHECK_CUDA(cudaFree(d_b));\n",
        "    CHECK_CUDA(cudaFree(d_c));\n",
        "    CHECK_CUDA(cudaEventDestroy(start_gpu));\n",
        "    CHECK_CUDA(cudaEventDestroy(stop_gpu));\n",
        "    printf(\"Part 2 Complete.\\n\\n\");\n",
        "\n",
        "\n",
        "    /*\n",
        "     * ----------------------------------------\n",
        "     * Part 3: Image Inversion\n",
        "     * ----------------------------------------\n",
        "     */\n",
        "    printf(\"--- Part 3: Image Inversion ---\\n\");\n",
        "\n",
        "    int width, height, channels;\n",
        "    const char* input_filename = \"input.jpg\";\n",
        "    const char* cpu_out_filename = \"cpu_inverted.png\";\n",
        "    const char* gpu_out_filename = \"gpu_inverted.png\";\n",
        "\n",
        "    // 1. Load image from disk (using stb_image)\n",
        "    unsigned char* h_img_in = stbi_load(input_filename, &width, &height, &channels, 0);\n",
        "    if (h_img_in == NULL) {\n",
        "        fprintf(stderr, \"ERROR: Failed to load input image '%s'.\\n\", input_filename);\n",
        "        fprintf(stderr, \"       Did you upload it to the Colab environment?\\n\");\n",
        "    } else {\n",
        "        printf(\"Loaded image '%s': %d x %d, %d channels\\n\", input_filename, width, height, channels);\n",
        "\n",
        "        if (channels < 3) {\n",
        "            fprintf(stderr, \"ERROR: Image must be RGB (3 channels) or RGBA (4 channels).\\n\");\n",
        "        } else {\n",
        "            size_t img_bytes = width * height * channels * sizeof(unsigned char);\n",
        "\n",
        "            // 2. Allocate host memory for output images\n",
        "            unsigned char* h_img_cpu_out = (unsigned char*)malloc(img_bytes);\n",
        "            unsigned char* h_img_gpu_out = (unsigned char*)malloc(img_bytes);\n",
        "            if (!h_img_cpu_out || !h_img_gpu_out) {\n",
        "                fprintf(stderr, \"Failed to allocate host memory for Part 3!\\n\");\n",
        "                stbi_image_free(h_img_in);\n",
        "                return 1;\n",
        "            }\n",
        "\n",
        "            // 3. --- Run CPU Version ---\n",
        "            printf(\"Running CPU image inversion...\\n\");\n",
        "            auto start_img_cpu = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "            cpuImageInvert(width, height, channels, h_img_in, h_img_cpu_out);\n",
        "\n",
        "            auto stop_img_cpu = std::chrono::high_resolution_clock::now();\n",
        "            auto duration_ms_img_cpu = std::chrono::duration_cast<std::chrono::microseconds>(stop_img_cpu - start_img_cpu).count() / 1000.0;\n",
        "            printf(\"CPU Time: %.3f ms\\n\", duration_ms_img_cpu);\n",
        "\n",
        "            // 4. --- Run GPU Version ---\n",
        "            printf(\"Running GPU image inversion...\\n\");\n",
        "\n",
        "            // 4a. Allocate Device (GPU) memory\n",
        "            unsigned char* d_img_in, * d_img_out;\n",
        "            CHECK_CUDA(cudaMalloc(&d_img_in, img_bytes));\n",
        "            CHECK_CUDA(cudaMalloc(&d_img_out, img_bytes));\n",
        "\n",
        "            // 4b. Create CUDA events for timing\n",
        "            cudaEvent_t start_img_gpu, stop_img_gpu;\n",
        "            CHECK_CUDA(cudaEventCreate(&start_img_gpu));\n",
        "            CHECK_CUDA(cudaEventCreate(&stop_img_gpu));\n",
        "\n",
        "            // 4c. Record start event\n",
        "            CHECK_CUDA(cudaEventRecord(start_img_gpu));\n",
        "\n",
        "            // 4d. Copy input image from Host to Device\n",
        "            CHECK_CUDA(cudaMemcpy(d_img_in, h_img_in, img_bytes, cudaMemcpyHostToDevice));\n",
        "\n",
        "            // 4e. Launch the GPU Kernel\n",
        "            // We'll launch one thread *per pixel*.\n",
        "            int num_pixels = width * height;\n",
        "            int imgThreadsPerBlock = 256;\n",
        "            int imgBlocksPerGrid = (num_pixels + imgThreadsPerBlock - 1) / imgThreadsPerBlock;\n",
        "\n",
        "            gpuImageInvert<<<imgBlocksPerGrid, imgThreadsPerBlock>>>(width, height, channels, d_img_in, d_img_out);\n",
        "\n",
        "            // 4f. Copy inverted image from Device to Host\n",
        "            CHECK_CUDA(cudaMemcpy(h_img_gpu_out, d_img_out, img_bytes, cudaMemcpyDeviceToHost));\n",
        "\n",
        "            // 4g. Record stop event and synchronize\n",
        "            CHECK_CUDA(cudaEventRecord(stop_img_gpu));\n",
        "            CHECK_CUDA(cudaEventSynchronize(stop_img_gpu));\n",
        "\n",
        "            // 4h. Calculate and print GPU time\n",
        "            float duration_ms_img_gpu = 0;\n",
        "            CHECK_CUDA(cudaEventElapsedTime(&duration_ms_img_gpu, start_img_gpu, stop_img_gpu));\n",
        "            printf(\"GPU Time: %.3f ms\\n\", duration_ms_img_gpu);\n",
        "\n",
        "            // 5. --- Save results and show speedup ---\n",
        "            printf(\"Saving output images...\\n\");\n",
        "            stbi_write_png(cpu_out_filename, width, height, channels, h_img_cpu_out, width * channels);\n",
        "            stbi_write_png(gpu_out_filename, width, height, channels, h_img_gpu_out, width * channels);\n",
        "            printf(\"Saved '%s' and '%s'.\\n\", cpu_out_filename, gpu_out_filename);\n",
        "            printf(\"Speedup (CPU Time / GPU Time): %.2fx\\n\", duration_ms_img_cpu / duration_ms_img_gpu);\n",
        "\n",
        "            // 6. --- Cleanup Part 3 ---\n",
        "            stbi_image_free(h_img_in); // Free original image\n",
        "            free(h_img_cpu_out);\n",
        "            free(h_img_gpu_out);\n",
        "            CHECK_CUDA(cudaFree(d_img_in));\n",
        "            CHECK_CUDA(cudaFree(d_img_out));\n",
        "            CHECK_CUDA(cudaEventDestroy(start_img_gpu));\n",
        "            CHECK_CUDA(cudaEventDestroy(stop_img_gpu));\n",
        "            printf(\"Part 3 Complete.\\n\");\n",
        "        }\n",
        "    }\n",
        "\n",
        "    printf(\"\\nAssignment Finished.\\n\");\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEvl_T7DjesO",
        "outputId": "6d360a5c-2e0b-4e76-dc6a-dd6dd9fd8cd2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_assignment.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/nothings/stb/master/stb_image.h\n",
        "!wget https://raw.githubusercontent.com/nothings/stb/master/stb_image_write.h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoiLwb6zj9u2",
        "outputId": "630618f2-7344-42a9-a077-f3ada897f692"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-29 06:10:23--  https://raw.githubusercontent.com/nothings/stb/master/stb_image.h\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 283010 (276K) [text/plain]\n",
            "Saving to: ‘stb_image.h’\n",
            "\n",
            "stb_image.h         100%[===================>] 276.38K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-10-29 06:10:23 (86.6 MB/s) - ‘stb_image.h’ saved [283010/283010]\n",
            "\n",
            "--2025-10-29 06:10:23--  https://raw.githubusercontent.com/nothings/stb/master/stb_image_write.h\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71221 (70K) [text/plain]\n",
            "Saving to: ‘stb_image_write.h’\n",
            "\n",
            "stb_image_write.h   100%[===================>]  69.55K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-10-29 06:10:24 (45.1 MB/s) - ‘stb_image_write.h’ saved [71221/71221]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc cuda_assignment.cu -o assignment_runner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwLKHjGbkdi_",
        "outputId": "242adaff-96d9-4a4d-c00d-b8b2c0899b6c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mstb_image.h(4276)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"old_limit\"\u001b[0m was set but never used\n",
            "     unsigned int cur, limit, old_limit;\n",
            "                              ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mstb_image.h(5185)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"idata_limit_old\"\u001b[0m was set but never used\n",
            "                 stbi__uint32 idata_limit_old = idata_limit;\n",
            "                              ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mstb_image.h(6972)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"out_size\"\u001b[0m was set but never used\n",
            "        int out_size = 0;\n",
            "            ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mstb_image.h(6973)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"delays_size\"\u001b[0m was set but never used\n",
            "        int delays_size = 0;\n",
            "            ^\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./assignment_runner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl5OWSKYl1ni",
        "outputId": "11372697-45c4-4199-8cc5-f438f2f050ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========================================\n",
            "PDC Lab Assignment #1: CUDA Introduction\n",
            "===========================================\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "\n",
            "--- Part 1: Hello GPU ---\n",
            "Part 1 Complete.\n",
            "\n",
            "--- Part 2: Vector Addition (N = 10,000,000) ---\n",
            "Running CPU vector addition...\n",
            "CPU Time: 46.296 ms\n",
            "Running GPU vector addition...\n",
            "GPU Time: 45.243 ms\n",
            "Verifying results...\n",
            "Error at index 0: CPU=1.23457, GPU=0.00000\n",
            "Results are INCORRECT!\n",
            "Part 2 Complete.\n",
            "\n",
            "--- Part 3: Image Inversion ---\n",
            "Loaded image 'input.jpg': 194 x 260, 3 channels\n",
            "Running CPU image inversion...\n",
            "CPU Time: 0.269 ms\n",
            "Running GPU image inversion...\n",
            "GPU Time: 0.162 ms\n",
            "Saving output images...\n",
            "Saved 'cpu_inverted.png' and 'gpu_inverted.png'.\n",
            "Speedup (CPU Time / GPU Time): 1.67x\n",
            "Part 3 Complete.\n",
            "\n",
            "Assignment Finished.\n"
          ]
        }
      ]
    }
  ]
}